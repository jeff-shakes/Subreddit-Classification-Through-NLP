{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70fccfc-ffa2-4d4c-976b-cab4d922edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_val_predict, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01520665-7e5e-4524-afef-fa08822dd729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/new_data_part1.csv')\n",
    "df2 = pd.read_csv('../data/new_data_part2.csv')\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7151b17c-5a58-479f-bb3d-0e49178cc2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10053, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07b3603f-3bbb-4772-8658-aca52ab90f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>adj_num</th>\n",
       "      <th>verb_num</th>\n",
       "      <th>noun_num</th>\n",
       "      <th>adv_num</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UFC Fight Pass Streaming Quality</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will UFC 284 sell 1,000,000 PPVs?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The ONE Championship team and CEO Chatri Sityo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yoel look tiny</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is your favorite prospect going into 2023?</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  adj_num  verb_num  \\\n",
       "0                   UFC Fight Pass Streaming Quality        0         0   \n",
       "1                  Will UFC 284 sell 1,000,000 PPVs?        0         1   \n",
       "2  The ONE Championship team and CEO Chatri Sityo...        0         0   \n",
       "3                                     Yoel look tiny        1         1   \n",
       "4     Who is your favorite prospect going into 2023?        1         2   \n",
       "\n",
       "   noun_num  adv_num  subreddit  selftext  word_count  \n",
       "0         5        0          1         0           5  \n",
       "1         2        0          1         0           6  \n",
       "2        12        0          0         0          18  \n",
       "3         1        0          1         0           3  \n",
       "4         1        0          1         0           8  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4575e5e-24de-421c-939c-4f0115ebc458",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'subreddit')\n",
    "y = df['subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f8170-9e68-4611-ab2b-cf64d02fdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_words_list= (['ufc', 'dana', 'white', 'ultimate', 'u.f.c.', 'islam', 'makhachev', 'moreno', 'edwards', 'usman', 'ngannou', 'adesanya',\n",
    "                  'pantoja', 'kara', 'kai', 'oliveira', 'pereira', 'sterling', 'royval', 'nicolau', 'perez', 'albazi', 'schnell', 'omalley', 'yan',\n",
    "                  'dvalishvili', 'vera', 'sandhagen', 'font', 'cruz', 'holloway', 'volkanovski', 'figueiredo', 'deiveson', 'aljamain', 'rodriguez',\n",
    "                  'ortega', 'allen', 'emmett', 'chan', 'sung', 'jung', 'kattar', 'giga', 'chikadze', 'poirier', 'jones', 'elliott', 'dvorak', 'molina', 'mokaev',\n",
    "                  'ulanbekov', 'yanez', 'gutierrez', 'nurmagomedov', 'simon', 'munhoz', 'shore', 'topuria', 'evloev', 'mitchell', 'yusuff', 'iga', 'barboza',\n",
    "                  'caceres', 'burns', 'neal', 'luque', 'fiziev', 'gamrot', 'anjos', 'tsarukyan', 'turner', 'hooker', 'ismagulov', 'gaethje', 'magny', 'whittaker',\n",
    "                  'vettori', 'strickland', 'costa', 'hermansson', 'covington', 'muniz', 'imavov', 'bachowicz', 'rakic', 'cannonier', 'dolidze', 'brunson', 'oezdemir',\n",
    "                  'spann', 'walker', 'nunes', 'weili', 'shevchenko', 'pena', 'blaydes', 'tuivasa', 'aspinall', 'andrade', 'santos', 'daukaus', 'tybura', 'lewis', 'holm',\n",
    "                  'vieira', 'jandiroba', 'maia', 'grasso', 'chookagian', 'murphy', 'fiorot', 'lemos', 'namajunas', 'esparza', 'jandiroba', 'blanchfield', 'barber',\n",
    "                  'calvillo', 'ribas', 'viana', 'ducote', 'pinheiro', 'xiaonan', 'yan', 'abdurakhimov', 'spivac', 'shamil', 'ketlen', 'pennington', 'miesha', 'kunitskaya',\n",
    "                  'rosa', 'avila', 'lansberg', 'paddy', 'silva', 'cormier', 'diaz', 'miocic', 'lesnar', 'penn', 'liddell', 'pierre', 'rousey', 'khabib', 'conor', 'mcgregor',\n",
    "                  'frevola', 'dillashaw', 'pimblett', 'helwani', 'blachowicz','arlovski', 'donatello', 'dec', 'december', 'jan', 'feb', 'selftext', 'says', 'did', 'does',\n",
    "                  'guy', 'guys', 'know', 'fc', 'vs', 'https', 'khamzat', '2022', '2023', '219', '281', '282', '283', '284', '285', 'going', 'man', 'got', 'anne', 'didnt', \n",
    "                  'ufc281', 'ankalaev', 'zhang', 'israel', 'johnson', 'dustin', 'krause', 'chandler', 'jiri', 'cejudo', 'march', 'february', 'gordon', 'ilia', 'florian',\n",
    "                  'makachov', 'beneil', 'dariush', 'jared', 'bryce', 'shavkat', 'november', 'saturday'])\n",
    "stop_words_list = text.ENGLISH_STOP_WORDS.union(my_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa7e542b-8ad3-48e3-9154-5cc0afcefcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([\n",
    "    ('cvec', CountVectorizer(max_features=4000,\n",
    "                             max_df = 0.1,\n",
    "                             min_df = 2,\n",
    "                             stop_words=stop_words_list,\n",
    "                             ngram_range=(1,1)), 'title')\n",
    "])\n",
    "\n",
    "lvl1_est_1 = [\n",
    "    ('nb', MultinomialNB()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('ada', AdaBoostClassifier())\n",
    "]\n",
    "\n",
    "lvl1_est_2 = [\n",
    "    ('nb', MultinomialNB()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('logr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "\n",
    "lvl1_est_3 = [\n",
    "    ('nb', MultinomialNB()),\n",
    "    ('logr', LogisticRegression(max_iter=1000)),\n",
    "    ('ada', AdaBoostClassifier())\n",
    "]\n",
    "\n",
    "lvl1_est_4 = [\n",
    "    ('logr', LogisticRegression(max_iter=1000)),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('ada', AdaBoostClassifier())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "04d43ccc-3d19-4ce0-a08c-614da2a1a78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7210505703709831\n",
      "Training Score: 0.901180527921475\n",
      "Testing Score: 0.7235481304693715\n"
     ]
    }
   ],
   "source": [
    "stacked_1 = StackingClassifier(estimators=lvl1_est_1, \n",
    "                               final_estimator=LogisticRegression(),\n",
    "                               n_jobs = -1)\n",
    "pipe01 = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('s1', stacked_1)\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipe01, X_train, y_train).mean())\n",
    "pipe01.fit(X_train, y_train)\n",
    "print(f'Training Score: {pipe01.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {pipe01.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dad76abc-e788-4e03-9421-6c8bf4e41613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7190624125434093\n",
      "Training Score: 0.9121899456161294\n",
      "Testing Score: 0.7287191726332538\n"
     ]
    }
   ],
   "source": [
    "#BEST MODEL THUS FAR (in terms test score and cross-val)\n",
    "stacked_2 = StackingClassifier(estimators=lvl1_est_2, \n",
    "                               final_estimator=LogisticRegression(),\n",
    "                               n_jobs = -1)\n",
    "pipe02 = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('s1', stacked_2)\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipe02, X_train, y_train).mean())\n",
    "pipe02.fit(X_train, y_train)\n",
    "print(f'Training Score: {pipe02.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {pipe02.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "d4afbff9-ee09-47cd-a267-3f96e8edd72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7197237823842404\n",
      "Training Score: 0.8379095370738825\n",
      "Testing Score: 0.7235481304693715\n"
     ]
    }
   ],
   "source": [
    "stacked_3 = StackingClassifier(estimators=lvl1_est_3, \n",
    "                               final_estimator=LogisticRegression(),\n",
    "                               n_jobs = -1)\n",
    "pipe03 = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('s1', stacked_3)\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipe03, X_train, y_train).mean())\n",
    "pipe03.fit(X_train, y_train)\n",
    "print(f'Training Score: {pipe03.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {pipe03.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3d4e354c-5a85-4c14-a8f6-03898cbd7a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7144184785765455\n",
      "Training Score: 0.9258522350444356\n",
      "Testing Score: 0.7231503579952268\n"
     ]
    }
   ],
   "source": [
    "stacked_4 = StackingClassifier(estimators=lvl1_est_4, \n",
    "                               final_estimator=LogisticRegression(),\n",
    "                               n_jobs = -1)\n",
    "pipe04 = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('s1', stacked_4)\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipe04, X_train, y_train).mean())\n",
    "pipe04.fit(X_train, y_train)\n",
    "print(f'Training Score: {pipe04.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {pipe04.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c033f-53fd-43fe-a748-03f726997e2c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Trying the best stacked model but with different final estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1e36d341-0f5f-42ba-8338-2ebabfa084a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6796662436481213\n",
      "Training Score: 0.8263695450324977\n",
      "Testing Score: 0.6992840095465394\n"
     ]
    }
   ],
   "source": [
    "stacked_5 = StackingClassifier(estimators=lvl1_est_2, \n",
    "                               final_estimator=KNeighborsClassifier(),\n",
    "                               n_jobs = -1)\n",
    "pipe05 = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('s1', stacked_5)\n",
    "])\n",
    "\n",
    "\n",
    "print(cross_val_score(pipe05, X_train, y_train).mean())\n",
    "pipe05.fit(X_train, y_train)\n",
    "print(f'Training Score: {pipe05.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {pipe05.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0bf1720a-c320-4cb1-82f2-e832c70f7388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6908096434147277\n",
      "Training Score: 0.8319405756731661\n",
      "Testing Score: 0.6865552903739062\n"
     ]
    }
   ],
   "source": [
    "stacked_5_2 = StackingClassifier(estimators=lvl1_est_2, \n",
    "                               final_estimator=KNeighborsClassifier(n_neighbors = 7),\n",
    "                               n_jobs = -1)\n",
    "pipe05 = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('s1', stacked_5_2)\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipe05, X_train, y_train).mean())\n",
    "pipe05.fit(X_train, y_train)\n",
    "print(f'Training Score: {pipe05.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {pipe05.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fcc973-9ec8-4e47-94a8-6f7c8e0130a3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b4d2a6-6561-45b7-94bc-be36c2fa9c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8792943361188487\n",
      "Testing Score: 0.7251392203659507\n"
     ]
    }
   ],
   "source": [
    "vote = VotingClassifier([\n",
    "    ('nb', MultinomialNB()),\n",
    "    ('rf', RandomForestClassifier(n_jobs = -1)),\n",
    "    ('logr', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('vote', vote)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(f'Training Score: {pipe.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {pipe.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "194e6b44-407f-426b-9d75-78befaf49db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8942830614139806\n",
      "Testing Score: 0.7267303102625299\n"
     ]
    }
   ],
   "source": [
    "vote = VotingClassifier([\n",
    "    ('nb', MultinomialNB()),\n",
    "    ('rf', RandomForestClassifier(n_jobs = -1)),\n",
    "    ('logr', LogisticRegression(max_iter=1000))\n",
    "], \n",
    "    voting = 'soft')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('vote', vote)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(f'Training Score: {pipe.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {pipe.score(X_test, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
